{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        # store the target image width, height,\n",
    "        # and interpolation method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        # resize the image to a fixed size, ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        # if the preprocessors are None, initialize them as an empty list\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "            \n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "        # initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # loop over the input images\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # load the image and extract the class label \n",
    "            # assuming that our path has the following format:\n",
    "            # /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            \n",
    "            # check to see if our preprocessors are not None\n",
    "            if self.preprocessors is not None:\n",
    "                # loop over the preprocessors and apply each to the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "                    \n",
    "            # treat our processed image as a \"feature vector\" \n",
    "            # by updating the data list followed by the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # show an update every 'verbose' images\n",
    "            if verbose > 0 and i >= 0 and (i + 1) % verbose == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i + 1, len(imagePaths)))\n",
    "                \n",
    "        # return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to input dataset\n",
    "dataset = './cat-dog-panda/animals/'\n",
    "# number of nearest neighbors for classification\n",
    "k = 1\n",
    "# number of jobs for k-NN distance (-1 uses all available cores)\n",
    "threads_num = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/3000\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1500/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2500/3000\n",
      "[INFO] processed 3000/3000\n",
      "[INFO] features matrix: 9.0MB\n",
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.39      0.51      0.44       249\n",
      "        dogs       0.38      0.43      0.41       262\n",
      "       panda       0.73      0.39      0.51       239\n",
      "\n",
      "    accuracy                           0.45       750\n",
      "   macro avg       0.50      0.44      0.45       750\n",
      "weighted avg       0.50      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = [file for file in glob.glob(dataset + \"**/*.jpg\", recursive=True)]\n",
    "\n",
    "# initialize the image preprocessor, load the dataset from disk,\n",
    "# and reshape the data matrix\n",
    "simplePreprocessor = SimplePreprocessor(32, 32)\n",
    "simpleDatasetLoader = SimpleDatasetLoader(preprocessors=[simplePreprocessor])\n",
    "(data, labels) = simpleDatasetLoader.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 32*32*3))\n",
    "\n",
    "# show information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# encode the labels as integers\n",
    "labelEncoder = LabelEncoder()\n",
    "labels = labelEncoder.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits \n",
    "# using 75% of the data for training\n",
    "# and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# train and evaluate a k-NN classifier on the raw pixel intensities\n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors=k, n_jobs=threads_num)\n",
    "model.fit(trainX, trainY)\n",
    "print(classification_report(testY, model.predict(testX), target_names=labelEncoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
