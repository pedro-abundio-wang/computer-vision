{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor(BaseLogger):\n",
    "    def __init__(self, figPath, jsonPath=None, startAt=0):\n",
    "        # store the output path for the figure, the path to the JSON\n",
    "        # serialized file, and the starting epoch\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.figPath = figPath\n",
    "        self.jsonPath = jsonPath\n",
    "        self.startAt = startAt\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        # initialize the history dictionary\n",
    "        self.H = {}\n",
    "        \n",
    "        # if the JSON history path exists, load the training history\n",
    "        if self.jsonPath is not None:\n",
    "            if os.path.exists(self.jsonPath):\n",
    "                self.H = json.loads(open(self.jsonPath).read())\n",
    "                \n",
    "                # check to see if a starting epoch was supplied\n",
    "                if self.startAt > 0:\n",
    "                    # loop over the entries in the history log and\n",
    "                    # trim any entries that are past the starting epoch\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.startAt]\n",
    "                        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # loop over the logs and update the loss, accuracy, etc.\n",
    "        # for the entire training process\n",
    "        for (k, v) in logs.items():\n",
    "            l = self.H.get(k, [])\n",
    "            l.append(v)\n",
    "            self.H[k] = l\n",
    "            \n",
    "        # check to see if the training history should be serialized to file\n",
    "        if self.jsonPath is not None:\n",
    "            f = open(self.jsonPath, \"w\")\n",
    "            f.write(json.dumps(self.H))\n",
    "            f.close()\n",
    "            \n",
    "        # ensure at least two epochs have passed before plotting\n",
    "        # (epoch starts at zero)\n",
    "        if len(self.H[\"loss\"]) > 1:\n",
    "            # plot the training loss and accuracy\n",
    "            N = np.arange(0, len(self.H[\"loss\"]))\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
    "            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.plot(N, self.H[\"acc\"], label=\"train_acc\")\n",
    "            plt.plot(N, self.H[\"val_acc\"], label=\"val_acc\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            \n",
    "            # save the figure\n",
    "            plt.savefig(self.figPath)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pedro/miniconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO process ID: 13254\n"
     ]
    }
   ],
   "source": [
    "# show information on the process ID\n",
    "print(\"[INFO process ID: {}\".format(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n"
     ]
    }
   ],
   "source": [
    "# load the training and testing data, then scale it into the\n",
    "# range [0, 1]\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "labelBinarizer = LabelBinarizer()\n",
    "trainY = labelBinarizer.fit_transform(trainY)\n",
    "testY = labelBinarizer.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "from classifiers.mini_vgg import MiniVGGNet\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "miniVGG = MiniVGGNet()\n",
    "model = miniVGG.build(width=32, height=32, depth=3, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the set of callbacks\n",
    "figPath = os.path.sep.join([\"output\", \"{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([\"output\", \"{}.json\".format(os.getpid())])\n",
    "callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.1668 - acc: 0.5981 - val_loss: 0.9382 - val_acc: 0.6704\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.9865 - acc: 0.6594 - val_loss: 0.9484 - val_acc: 0.6763\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.8701 - acc: 0.6974 - val_loss: 0.7887 - val_acc: 0.7246\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.7935 - acc: 0.7225 - val_loss: 0.7401 - val_acc: 0.7461\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.7239 - acc: 0.7476 - val_loss: 0.6795 - val_acc: 0.7649\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.6807 - acc: 0.7639 - val_loss: 0.6616 - val_acc: 0.7742\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.6325 - acc: 0.7769 - val_loss: 0.6647 - val_acc: 0.7741\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.5900 - acc: 0.7927 - val_loss: 0.6064 - val_acc: 0.7933\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.5524 - acc: 0.8050 - val_loss: 0.6808 - val_acc: 0.7724\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.5196 - acc: 0.8159 - val_loss: 0.6417 - val_acc: 0.7870\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.4900 - acc: 0.8276 - val_loss: 0.5926 - val_acc: 0.8009\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.4612 - acc: 0.8368 - val_loss: 0.6045 - val_acc: 0.8048\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.4357 - acc: 0.8460 - val_loss: 0.5944 - val_acc: 0.8059\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.4129 - acc: 0.8529 - val_loss: 0.5872 - val_acc: 0.8062\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.3869 - acc: 0.8632 - val_loss: 0.6012 - val_acc: 0.8095\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3702 - acc: 0.8696 - val_loss: 0.6347 - val_acc: 0.7997\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3531 - acc: 0.8745 - val_loss: 0.7123 - val_acc: 0.7823\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3428 - acc: 0.8785 - val_loss: 0.5660 - val_acc: 0.8193\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3274 - acc: 0.8829 - val_loss: 0.6287 - val_acc: 0.8087\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.3005 - acc: 0.8908 - val_loss: 0.5725 - val_acc: 0.8209\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2961 - acc: 0.8946 - val_loss: 0.5889 - val_acc: 0.8144\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2806 - acc: 0.8992 - val_loss: 0.5917 - val_acc: 0.8139\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2769 - acc: 0.9021 - val_loss: 0.5949 - val_acc: 0.8182\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2568 - acc: 0.9083 - val_loss: 0.5995 - val_acc: 0.8197\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2495 - acc: 0.9095 - val_loss: 0.5888 - val_acc: 0.8216\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2438 - acc: 0.9116 - val_loss: 0.5855 - val_acc: 0.8231\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2302 - acc: 0.9169 - val_loss: 0.5909 - val_acc: 0.8208\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2270 - acc: 0.9201 - val_loss: 0.5879 - val_acc: 0.8224\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2157 - acc: 0.9224 - val_loss: 0.5933 - val_acc: 0.8250\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2111 - acc: 0.9259 - val_loss: 0.5935 - val_acc: 0.8228\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2028 - acc: 0.9288 - val_loss: 0.6354 - val_acc: 0.8237\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2054 - acc: 0.9258 - val_loss: 0.5983 - val_acc: 0.8266\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1919 - acc: 0.9310 - val_loss: 0.5952 - val_acc: 0.8258\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1914 - acc: 0.9304 - val_loss: 0.5934 - val_acc: 0.8288\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1802 - acc: 0.9376 - val_loss: 0.5974 - val_acc: 0.8319\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.1783 - acc: 0.9362 - val_loss: 0.6074 - val_acc: 0.8330\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1710 - acc: 0.9388 - val_loss: 0.6394 - val_acc: 0.8178\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1700 - acc: 0.9387 - val_loss: 0.5978 - val_acc: 0.8342\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1653 - acc: 0.9413 - val_loss: 0.6059 - val_acc: 0.8360\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1596 - acc: 0.9437 - val_loss: 0.6066 - val_acc: 0.8355\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1597 - acc: 0.9433 - val_loss: 0.6108 - val_acc: 0.8306\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1552 - acc: 0.9439 - val_loss: 0.6096 - val_acc: 0.8329\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1567 - acc: 0.9438 - val_loss: 0.5909 - val_acc: 0.8325\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1548 - acc: 0.9461 - val_loss: 0.6692 - val_acc: 0.8149\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1487 - acc: 0.9469 - val_loss: 0.6256 - val_acc: 0.8317\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1453 - acc: 0.9495 - val_loss: 0.6362 - val_acc: 0.8248\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1382 - acc: 0.9511 - val_loss: 0.6363 - val_acc: 0.8328\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1372 - acc: 0.9527 - val_loss: 0.6145 - val_acc: 0.8319\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1341 - acc: 0.9524 - val_loss: 0.6359 - val_acc: 0.8304\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1338 - acc: 0.9530 - val_loss: 0.6209 - val_acc: 0.8322\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1277 - acc: 0.9551 - val_loss: 0.6689 - val_acc: 0.8255\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1265 - acc: 0.9544 - val_loss: 0.6404 - val_acc: 0.8343\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1234 - acc: 0.9562 - val_loss: 0.6181 - val_acc: 0.8348\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1188 - acc: 0.9589 - val_loss: 0.6339 - val_acc: 0.8318\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1231 - acc: 0.9571 - val_loss: 0.6110 - val_acc: 0.8363\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1138 - acc: 0.9590 - val_loss: 0.6451 - val_acc: 0.8325\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1133 - acc: 0.9608 - val_loss: 0.6454 - val_acc: 0.8356\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1115 - acc: 0.9624 - val_loss: 0.6415 - val_acc: 0.8366\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1114 - acc: 0.9606 - val_loss: 0.6578 - val_acc: 0.8346\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1125 - acc: 0.9599 - val_loss: 0.6163 - val_acc: 0.8365\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1094 - acc: 0.9616 - val_loss: 0.6135 - val_acc: 0.8395\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1047 - acc: 0.9629 - val_loss: 0.6274 - val_acc: 0.8416\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1059 - acc: 0.9626 - val_loss: 0.6330 - val_acc: 0.8355\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.1068 - acc: 0.9618 - val_loss: 0.6287 - val_acc: 0.8380\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1076 - acc: 0.9627 - val_loss: 0.6439 - val_acc: 0.8408\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1035 - acc: 0.9643 - val_loss: 0.6343 - val_acc: 0.8385\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1002 - acc: 0.9653 - val_loss: 0.6198 - val_acc: 0.8412\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0967 - acc: 0.9648 - val_loss: 0.6476 - val_acc: 0.8416\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0969 - acc: 0.9655 - val_loss: 0.6518 - val_acc: 0.8343\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0962 - acc: 0.9655 - val_loss: 0.6635 - val_acc: 0.8362\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0991 - acc: 0.9647 - val_loss: 0.6561 - val_acc: 0.8360\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0963 - acc: 0.9662 - val_loss: 0.6416 - val_acc: 0.8404\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.0957 - acc: 0.9665 - val_loss: 0.6522 - val_acc: 0.8371\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0929 - acc: 0.9672 - val_loss: 0.6472 - val_acc: 0.8400\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0958 - acc: 0.9666 - val_loss: 0.6695 - val_acc: 0.8361\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0871 - acc: 0.9693 - val_loss: 0.6588 - val_acc: 0.8320\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0882 - acc: 0.9690 - val_loss: 0.6833 - val_acc: 0.8323\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0918 - acc: 0.9682 - val_loss: 0.6700 - val_acc: 0.8390\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0934 - acc: 0.9682 - val_loss: 0.6784 - val_acc: 0.8357\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.0876 - acc: 0.9686 - val_loss: 0.6617 - val_acc: 0.8393\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0874 - acc: 0.9696 - val_loss: 0.6484 - val_acc: 0.8386\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0867 - acc: 0.9695 - val_loss: 0.6675 - val_acc: 0.8374\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0870 - acc: 0.9698 - val_loss: 0.6528 - val_acc: 0.8353\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0864 - acc: 0.9688 - val_loss: 0.6632 - val_acc: 0.8385\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0837 - acc: 0.9708 - val_loss: 0.6693 - val_acc: 0.8399\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0843 - acc: 0.9704 - val_loss: 0.6473 - val_acc: 0.8428\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.0857 - acc: 0.9705 - val_loss: 0.6974 - val_acc: 0.8377\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0848 - acc: 0.9700 - val_loss: 0.6796 - val_acc: 0.8382\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0815 - acc: 0.9710 - val_loss: 0.6894 - val_acc: 0.8369\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.0786 - acc: 0.9717 - val_loss: 0.6861 - val_acc: 0.8348\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0784 - acc: 0.9728 - val_loss: 0.6663 - val_acc: 0.8352\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.0919 - acc: 0.9682 - val_loss: 0.6735 - val_acc: 0.8379\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.0841 - acc: 0.9702 - val_loss: 0.6776 - val_acc: 0.8379\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.0816 - acc: 0.9710 - val_loss: 0.6567 - val_acc: 0.8377\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0774 - acc: 0.9737 - val_loss: 0.6720 - val_acc: 0.8434\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.0745 - acc: 0.9740 - val_loss: 0.6488 - val_acc: 0.8403\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0729 - acc: 0.9749 - val_loss: 0.6757 - val_acc: 0.8414\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.0752 - acc: 0.9741 - val_loss: 0.6616 - val_acc: 0.8394\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.0750 - acc: 0.9739 - val_loss: 0.6457 - val_acc: 0.8432\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0778 - acc: 0.9731 - val_loss: 0.6922 - val_acc: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc75de07b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=100, callbacks=callbacks, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
