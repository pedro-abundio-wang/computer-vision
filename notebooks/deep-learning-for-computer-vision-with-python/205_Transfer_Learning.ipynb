{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n",
      "[INFO] showing layers...\n",
      "[INFO] 0\tInputLayer\n",
      "[INFO] 1\tConv2D\n",
      "[INFO] 2\tConv2D\n",
      "[INFO] 3\tMaxPooling2D\n",
      "[INFO] 4\tConv2D\n",
      "[INFO] 5\tConv2D\n",
      "[INFO] 6\tMaxPooling2D\n",
      "[INFO] 7\tConv2D\n",
      "[INFO] 8\tConv2D\n",
      "[INFO] 9\tConv2D\n",
      "[INFO] 10\tMaxPooling2D\n",
      "[INFO] 11\tConv2D\n",
      "[INFO] 12\tConv2D\n",
      "[INFO] 13\tConv2D\n",
      "[INFO] 14\tMaxPooling2D\n",
      "[INFO] 15\tConv2D\n",
      "[INFO] 16\tConv2D\n",
      "[INFO] 17\tConv2D\n",
      "[INFO] 18\tMaxPooling2D\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications import VGG16\n",
    "import argparse\n",
    "\n",
    "# whether or not to include top of CNN\n",
    "include_top = -1\n",
    "\n",
    "# load the VGG16 network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=include_top>0)\n",
    "print(\"[INFO] showing layers...\")\n",
    "\n",
    "# loop over the layers in the network and display them to the console\n",
    "for (i, layer) in enumerate(model.layers):\n",
    "    print(\"[INFO] {}\\t{}\".format(i, layer.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCHeadNet:\n",
    "    \n",
    "    def build(self, baseModel, classes, D):\n",
    "        # initialize the head model that will be placed on top of\n",
    "        # the base, then add a FC layer\n",
    "        headModel = baseModel.output\n",
    "        headModel = Flatten(name=\"flatten\")(headModel)\n",
    "        headModel = Dense(D, activation=\"relu\")(headModel)\n",
    "        headModel = Dropout(0.5)(headModel)\n",
    "\n",
    "        # add a softmax layer\n",
    "        headModel = Dense(classes, activation=\"softmax\")(headModel)\n",
    "\n",
    "        # return the model\n",
    "        return headModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from utils.image_preprocessor import ImagePreprocessor\n",
    "from utils.image_preprocessor import AspectAwarePreprocessor\n",
    "from utils.image_preprocessor import ImageToArrayPreprocessor\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_num = 1000\n",
    "test_sample_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX[:train_sample_num]\n",
    "trainY = trainY[:train_sample_num]\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 32, 32, 3)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "testX = testX[:test_sample_num]\n",
    "testY = testY[:test_sample_num]\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "ip = ImagePreprocessor(preprocessors=[aap, iap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = ip.preprocess(trainX)\n",
    "testX = ip.preprocess(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 224, 224, 3)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to output model\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 4.3442 - acc: 0.1270 - val_loss: 2.2730 - val_acc: 0.2000\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 2.2723 - acc: 0.1692 - val_loss: 2.2326 - val_acc: 0.1500\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 2.2250 - acc: 0.1410 - val_loss: 2.2035 - val_acc: 0.2100\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 2.2204 - acc: 0.1643 - val_loss: 2.2676 - val_acc: 0.1900\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 2.1276 - acc: 0.2017 - val_loss: 2.1751 - val_acc: 0.2250\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.1311 - acc: 0.2078 - val_loss: 2.0260 - val_acc: 0.2450\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 2.1026 - acc: 0.1885 - val_loss: 2.0816 - val_acc: 0.2500\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.0817 - acc: 0.2076 - val_loss: 2.1218 - val_acc: 0.2450\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 2.1127 - acc: 0.2067 - val_loss: 2.0607 - val_acc: 0.2250\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 2.0769 - acc: 0.2008 - val_loss: 2.0515 - val_acc: 0.2150\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.0960 - acc: 0.2026 - val_loss: 2.0435 - val_acc: 0.2800\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.0201 - acc: 0.2257 - val_loss: 1.9650 - val_acc: 0.2700\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.0325 - acc: 0.2238 - val_loss: 1.9754 - val_acc: 0.2350\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 2.0172 - acc: 0.2226 - val_loss: 1.9348 - val_acc: 0.2750\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.0457 - acc: 0.2339 - val_loss: 2.0061 - val_acc: 0.2650\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9804 - acc: 0.2399 - val_loss: 1.9226 - val_acc: 0.3250\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9898 - acc: 0.2508 - val_loss: 1.9431 - val_acc: 0.3450\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9628 - acc: 0.2288 - val_loss: 1.8306 - val_acc: 0.3650\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9521 - acc: 0.2732 - val_loss: 1.8169 - val_acc: 0.3300\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9610 - acc: 0.2661 - val_loss: 1.9099 - val_acc: 0.3350\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9364 - acc: 0.2732 - val_loss: 1.8024 - val_acc: 0.3200\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9662 - acc: 0.2521 - val_loss: 1.8426 - val_acc: 0.3250\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9151 - acc: 0.2740 - val_loss: 1.8571 - val_acc: 0.2600\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9339 - acc: 0.2560 - val_loss: 1.8282 - val_acc: 0.3150\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.9529 - acc: 0.2399 - val_loss: 1.8970 - val_acc: 0.3100\n",
      "[INFO] evaluating after initialization...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.33      0.05      0.09        20\n",
      "  automobile       0.12      0.14      0.13        14\n",
      "        bird       0.21      0.24      0.22        21\n",
      "         cat       0.00      0.00      0.00        19\n",
      "        deer       0.00      0.00      0.00        15\n",
      "         dog       0.00      0.00      0.00        18\n",
      "        frog       0.32      0.81      0.46        26\n",
      "       horse       0.27      0.33      0.30        18\n",
      "        ship       0.53      0.36      0.43        28\n",
      "       truck       0.35      0.81      0.49        21\n",
      "\n",
      "    accuracy                           0.31       200\n",
      "   macro avg       0.21      0.27      0.21       200\n",
      "weighted avg       0.24      0.31      0.24       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# initialize the new head of the network, a set of FC layers\n",
    "# followed by a softmax classifier\n",
    "headModel = FCHeadNet().build(baseModel, len(labelNames), 256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will\n",
    "# become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they\n",
    "# will *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other\n",
    "# layers are frozen) -- this will allow the new FC layers to\n",
    "# start to become initialized with actual \"learned\" values\n",
    "# versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), \n",
    "                    validation_data=(testX, testY), epochs=25, \n",
    "                    steps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), \n",
    "                    validation_data=(testX, testY), epochs=100, \n",
    "                    steps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network on the fine-tuned model\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(args[\"model\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
