{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to output model\n",
    "model_path = \"./output/model_persistence/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n"
     ]
    }
   ],
   "source": [
    "# load the training and testing data, then scale it into the range [0, 1]\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "labelBinarizer = LabelBinarizer()\n",
    "trainY = labelBinarizer.fit_transform(trainY)\n",
    "testY = labelBinarizer.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "from classifiers.mini_vgg import MiniVGGNet\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.01, decay=0.01/40, momentum=0.9, nesterov=True)\n",
    "miniVGG = MiniVGGNet()\n",
    "model = miniVGG.build(width=32, height=32, depth=3, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the callback to save only the *best* model to disk\n",
    "# based on the validation loss\n",
    "fname = os.path.sep.join([model_path, \"minivgg-weights-{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
    "checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.5632 - acc: 0.8016 - val_loss: 0.6082 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60823, saving model to ./output/model_persistence//minivgg-weights-001-0.6082.hdf5\n",
      "Epoch 2/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.5420 - acc: 0.8087 - val_loss: 0.5775 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60823 to 0.57755, saving model to ./output/model_persistence//minivgg-weights-002-0.5775.hdf5\n",
      "Epoch 3/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.5183 - acc: 0.8162 - val_loss: 0.5882 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.57755\n",
      "Epoch 4/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.4959 - acc: 0.8246 - val_loss: 0.5866 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.57755\n",
      "Epoch 5/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.4809 - acc: 0.8300 - val_loss: 0.5783 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57755\n",
      "Epoch 6/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.4632 - acc: 0.8349 - val_loss: 0.5650 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.57755 to 0.56503, saving model to ./output/model_persistence//minivgg-weights-006-0.5650.hdf5\n",
      "Epoch 7/40\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.4462 - acc: 0.8412 - val_loss: 0.5734 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56503\n",
      "Epoch 8/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.4294 - acc: 0.8461 - val_loss: 0.5637 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56503 to 0.56374, saving model to ./output/model_persistence//minivgg-weights-008-0.5637.hdf5\n",
      "Epoch 9/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.4161 - acc: 0.8509 - val_loss: 0.5701 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56374\n",
      "Epoch 10/40\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.4074 - acc: 0.8538 - val_loss: 0.5598 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56374 to 0.55980, saving model to ./output/model_persistence//minivgg-weights-010-0.5598.hdf5\n",
      "Epoch 11/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.3924 - acc: 0.8587 - val_loss: 0.5543 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.55980 to 0.55431, saving model to ./output/model_persistence//minivgg-weights-011-0.5543.hdf5\n",
      "Epoch 12/40\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.3836 - acc: 0.8632 - val_loss: 0.5694 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.55431\n",
      "Epoch 13/40\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.3714 - acc: 0.8675 - val_loss: 0.5577 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.55431\n",
      "Epoch 14/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.3625 - acc: 0.8725 - val_loss: 0.5534 - val_acc: 0.8193\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55431 to 0.55345, saving model to ./output/model_persistence//minivgg-weights-014-0.5534.hdf5\n",
      "Epoch 15/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.3528 - acc: 0.8734 - val_loss: 0.5768 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.55345\n",
      "Epoch 16/40\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.3397 - acc: 0.8800 - val_loss: 0.6687 - val_acc: 0.7971\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.55345\n",
      "Epoch 17/40\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.3351 - acc: 0.8805 - val_loss: 0.5746 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.55345\n",
      "Epoch 18/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.3226 - acc: 0.8854 - val_loss: 0.5728 - val_acc: 0.8179\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.55345\n",
      "Epoch 19/40\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.3192 - acc: 0.8861 - val_loss: 0.5692 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.55345\n",
      "Epoch 20/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.3083 - acc: 0.8889 - val_loss: 0.5596 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55345\n",
      "Epoch 21/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.3021 - acc: 0.8922 - val_loss: 0.5608 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.55345\n",
      "Epoch 22/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.3018 - acc: 0.8913 - val_loss: 0.5752 - val_acc: 0.8171\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55345\n",
      "Epoch 23/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2914 - acc: 0.8946 - val_loss: 0.5588 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.55345\n",
      "Epoch 24/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2858 - acc: 0.8972 - val_loss: 0.5682 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.55345\n",
      "Epoch 25/40\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2760 - acc: 0.8998 - val_loss: 0.5628 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.55345\n",
      "Epoch 26/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2726 - acc: 0.9029 - val_loss: 0.5642 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.55345\n",
      "Epoch 27/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2707 - acc: 0.9018 - val_loss: 0.5559 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.55345\n",
      "Epoch 28/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2629 - acc: 0.9049 - val_loss: 0.5607 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.55345\n",
      "Epoch 29/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2584 - acc: 0.9077 - val_loss: 0.5603 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.55345\n",
      "Epoch 30/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2568 - acc: 0.9086 - val_loss: 0.5734 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.55345\n",
      "Epoch 31/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.2516 - acc: 0.9087 - val_loss: 0.5711 - val_acc: 0.8227\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.55345\n",
      "Epoch 32/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.2430 - acc: 0.9127 - val_loss: 0.5676 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.55345\n",
      "Epoch 33/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2444 - acc: 0.9125 - val_loss: 0.5838 - val_acc: 0.8175\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.55345\n",
      "Epoch 34/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2440 - acc: 0.9130 - val_loss: 0.5817 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.55345\n",
      "Epoch 35/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.2372 - acc: 0.9143 - val_loss: 0.5938 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.55345\n",
      "Epoch 36/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2302 - acc: 0.9170 - val_loss: 0.5811 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.55345\n",
      "Epoch 37/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.2289 - acc: 0.9173 - val_loss: 0.5780 - val_acc: 0.8265\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.55345\n",
      "Epoch 38/40\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.2206 - acc: 0.9210 - val_loss: 0.5864 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.55345\n",
      "Epoch 39/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2221 - acc: 0.9199 - val_loss: 0.5702 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.55345\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.2181 - acc: 0.9229 - val_loss: 0.5765 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.55345\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), \n",
    "              batch_size=64, epochs=40, \n",
    "              callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the callback to save only the *best* model to disk\n",
    "# based on the validation loss\n",
    "fname = os.path.sep.join([model_path, \"minivgg-weights-best.hdf5\"])\n",
    "checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2143 - acc: 0.9236 - val_loss: 0.5947 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59468, saving model to ./output/model_persistence//minivgg-weights-best.hdf5\n",
      "Epoch 2/40\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 0.2135 - acc: 0.9235 - val_loss: 0.5719 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59468 to 0.57188, saving model to ./output/model_persistence//minivgg-weights-best.hdf5\n",
      "Epoch 3/40\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 0.2090 - acc: 0.9247 - val_loss: 0.5766 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.57188\n",
      "Epoch 4/40\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.2092 - acc: 0.9244 - val_loss: 0.5873 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.57188\n",
      "Epoch 5/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.2023 - acc: 0.9269 - val_loss: 0.5830 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.57188\n",
      "Epoch 6/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2022 - acc: 0.9269 - val_loss: 0.6088 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.57188\n",
      "Epoch 7/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.2009 - acc: 0.9274 - val_loss: 0.5818 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.57188\n",
      "Epoch 8/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.1960 - acc: 0.9290 - val_loss: 0.5826 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57188\n",
      "Epoch 9/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1990 - acc: 0.9281 - val_loss: 0.5865 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57188\n",
      "Epoch 10/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1920 - acc: 0.9319 - val_loss: 0.5914 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57188\n",
      "Epoch 11/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1915 - acc: 0.9308 - val_loss: 0.5895 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.57188\n",
      "Epoch 12/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1884 - acc: 0.9331 - val_loss: 0.5812 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.57188\n",
      "Epoch 13/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1877 - acc: 0.9328 - val_loss: 0.5837 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.57188\n",
      "Epoch 14/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1840 - acc: 0.9341 - val_loss: 0.5961 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.57188\n",
      "Epoch 15/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.1853 - acc: 0.9331 - val_loss: 0.5894 - val_acc: 0.8278\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.57188\n",
      "Epoch 16/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1830 - acc: 0.9330 - val_loss: 0.5975 - val_acc: 0.8271\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57188\n",
      "Epoch 17/40\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1809 - acc: 0.9349 - val_loss: 0.5891 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57188\n",
      "Epoch 18/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1787 - acc: 0.9362 - val_loss: 0.5890 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.57188\n",
      "Epoch 19/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1739 - acc: 0.9376 - val_loss: 0.5966 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.57188\n",
      "Epoch 20/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1768 - acc: 0.9371 - val_loss: 0.5868 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.57188\n",
      "Epoch 21/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1740 - acc: 0.9382 - val_loss: 0.5949 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.57188\n",
      "Epoch 22/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1751 - acc: 0.9376 - val_loss: 0.5942 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.57188\n",
      "Epoch 23/40\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.1724 - acc: 0.9386 - val_loss: 0.5866 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.57188\n",
      "Epoch 24/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1667 - acc: 0.9405 - val_loss: 0.5982 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.57188\n",
      "Epoch 25/40\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1628 - acc: 0.9418 - val_loss: 0.5922 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.57188\n",
      "Epoch 26/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.1701 - acc: 0.9400 - val_loss: 0.5914 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.57188\n",
      "Epoch 27/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1672 - acc: 0.9394 - val_loss: 0.6126 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.57188\n",
      "Epoch 28/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1620 - acc: 0.9429 - val_loss: 0.5979 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.57188\n",
      "Epoch 29/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1607 - acc: 0.9431 - val_loss: 0.6014 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.57188\n",
      "Epoch 30/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1602 - acc: 0.9430 - val_loss: 0.5984 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.57188\n",
      "Epoch 31/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.1577 - acc: 0.9447 - val_loss: 0.6037 - val_acc: 0.8249\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.57188\n",
      "Epoch 32/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.1578 - acc: 0.9446 - val_loss: 0.5992 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.57188\n",
      "Epoch 33/40\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.1562 - acc: 0.9433 - val_loss: 0.6054 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.57188\n",
      "Epoch 34/40\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.1543 - acc: 0.9452 - val_loss: 0.5983 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.57188\n",
      "Epoch 35/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1561 - acc: 0.9447 - val_loss: 0.6123 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.57188\n",
      "Epoch 36/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1520 - acc: 0.9464 - val_loss: 0.6052 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.57188\n",
      "Epoch 37/40\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.1480 - acc: 0.9480 - val_loss: 0.6089 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.57188\n",
      "Epoch 38/40\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.1526 - acc: 0.9462 - val_loss: 0.5992 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.57188\n",
      "Epoch 39/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1516 - acc: 0.9459 - val_loss: 0.6164 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.57188\n",
      "Epoch 40/40\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1451 - acc: 0.9478 - val_loss: 0.6185 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.57188\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), \n",
    "              batch_size=64, epochs=40, \n",
    "              callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
