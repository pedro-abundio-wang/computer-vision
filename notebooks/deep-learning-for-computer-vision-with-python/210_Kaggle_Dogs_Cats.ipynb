{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training AlexNet on Kaggle: Dogs vs. Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "\n",
    "# import the necessary packages\n",
    "from utils.image_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.image_preprocessor import ResizePreprocessor\n",
    "from utils.image_preprocessor import PatchPreprocessor\n",
    "from utils.image_preprocessor import MeanPreprocessor\n",
    "from utils.hdf5_dataset_generator import HDF5DatasetGenerator\n",
    "from classifiers.alexnet import AlexNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class TrainingMonitor(BaseLogger):\n",
    "    \n",
    "    def __init__(self, figPath, jsonPath=None, startAt=0):\n",
    "        # store the output path for the figure, the path to the JSON\n",
    "        # serialized file, and the starting epoch\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.figPath = figPath\n",
    "        self.jsonPath = jsonPath\n",
    "        self.startAt = startAt\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        # initialize the history dictionary\n",
    "        self.H = {}\n",
    "        \n",
    "        # if the JSON history path exists, load the training history\n",
    "        if self.jsonPath is not None:\n",
    "            if os.path.exists(self.jsonPath):\n",
    "                self.H = json.loads(open(self.jsonPath).read())\n",
    "                \n",
    "                # check to see if a starting epoch was supplied\n",
    "                if self.startAt > 0:\n",
    "                    # loop over the entries in the history log and\n",
    "                    # trim any entries that are past the starting epoch\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.startAt]\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # loop over the logs and update the loss, accuracy, etc.\n",
    "        # for the entire training process\n",
    "        for (k, v) in logs.items():\n",
    "            l = self.H.get(k, [])\n",
    "            l.append(v)\n",
    "            self.H[k] = l\n",
    "            \n",
    "        # check to see if the training history should be serialized to file\n",
    "        if self.jsonPath is not None:\n",
    "            f = open(self.jsonPath, \"w\")\n",
    "            f.write(json.dumps(self.H))\n",
    "            f.close()\n",
    "            \n",
    "        # ensure at least two epochs have passed before plotting\n",
    "        # (epoch starts at zero)\n",
    "        if len(self.H[\"loss\"]) > 1:\n",
    "            # plot the training loss and accuracy\n",
    "            N = np.arange(0, len(self.H[\"loss\"]))\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
    "            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.plot(N, self.H[\"acc\"], label=\"train_acc\")\n",
    "            plt.plot(N, self.H[\"val_acc\"], label=\"val_acc\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            \n",
    "            # save the figure\n",
    "            plt.savefig(self.figPath)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths to the images directory\n",
    "IMAGES_PATH = \"./datasets/kaggle_dogs_vs_cats/train\"\n",
    "\n",
    "# since we do not have validation data or access to the testing\n",
    "# labels we need to take a number of images from the training\n",
    "# data and use them instead\n",
    "NUM_CLASSES = 2\n",
    "NUM_VAL_IMAGES = 1250 * NUM_CLASSES\n",
    "NUM_TEST_IMAGES = 1250 * NUM_CLASSES\n",
    "\n",
    "# define the path to the output training, validation, and testing\n",
    "# HDF5 files\n",
    "TRAIN_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/train.hdf5\"\n",
    "VAL_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/val.hdf5\"\n",
    "TEST_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/test.hdf5\"\n",
    "\n",
    "# path to the output model file\n",
    "MODEL_PATH = \"./output/kaggle_dogs_vs_cats/alexnet_dogs_vs_cats.model\"\n",
    "\n",
    "# define the path to the dataset mean\n",
    "DATASET_MEAN = \"./output/kaggle_dogs_vs_cats/dogs_vs_cats_mean.json\"\n",
    "\n",
    "# define the path to the output directory used for storing plots,\n",
    "# classification reports, etc.\n",
    "OUTPUT_PATH = \"./output/kaggle_dogs_vs_cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, \n",
    "                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, \n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RGB means for the training set\n",
    "means = json.loads(open(DATASET_MEAN).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image preprocessors\n",
    "rp = ResizePreprocessor(227, 227)\n",
    "pp = PatchPreprocessor(227, 227)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/deep-learning/computer-vision/notebooks/deep-learning-for-computer-vision-with-python/utils/hdf5_dataset_generator.py:20: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  self.db = h5py.File(dbPath)\n"
     ]
    }
   ],
   "source": [
    "# initialize the training and validation dataset generators\n",
    "batch_size = 16\n",
    "trainGen = HDF5DatasetGenerator(TRAIN_HDF5, batch_size, aug=aug, preprocessors=[pp, mp, iap], classes=2)\n",
    "valGen = HDF5DatasetGenerator(VAL_HDF5, batch_size, preprocessors=[rp, mp, iap], classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = AlexNet.build(width=227, height=227, depth=3, classes=2, reg=0.0002)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# construct the set of callbacks\n",
    "path = os.path.sep.join([OUTPUT_PATH, \"{}.png\".format(os.getpid())])\n",
    "callbacks = [TrainingMonitor(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "1250/1250 [==============================] - 422s 337ms/step - loss: 3.6979 - acc: 0.5383 - val_loss: 3.0082 - val_acc: 0.5909\n",
      "Epoch 2/75\n",
      "1250/1250 [==============================] - 406s 325ms/step - loss: 2.3321 - acc: 0.5517 - val_loss: 2.2217 - val_acc: 0.5399\n",
      "Epoch 3/75\n",
      "1250/1250 [==============================] - 460s 368ms/step - loss: 2.2386 - acc: 0.5277 - val_loss: 1.9910 - val_acc: 0.5399\n",
      "Epoch 4/75\n",
      "1250/1250 [==============================] - 423s 339ms/step - loss: 2.3746 - acc: 0.5425 - val_loss: 2.1252 - val_acc: 0.5169\n",
      "Epoch 5/75\n",
      "1250/1250 [==============================] - 425s 340ms/step - loss: 2.6277 - acc: 0.5607 - val_loss: 2.7544 - val_acc: 0.5962\n",
      "Epoch 6/75\n",
      "1250/1250 [==============================] - 422s 338ms/step - loss: 2.6493 - acc: 0.5321 - val_loss: 2.4428 - val_acc: 0.5338\n",
      "Epoch 7/75\n",
      "1250/1250 [==============================] - 418s 335ms/step - loss: 2.5174 - acc: 0.5109 - val_loss: 6.9522 - val_acc: 0.4819\n",
      "Epoch 8/75\n",
      "1250/1250 [==============================] - 416s 333ms/step - loss: 2.6414 - acc: 0.5185 - val_loss: 2.1905 - val_acc: 0.5435\n",
      "Epoch 9/75\n",
      "1250/1250 [==============================] - 420s 336ms/step - loss: 2.3064 - acc: 0.5231 - val_loss: 1.8486 - val_acc: 0.5024\n",
      "Epoch 10/75\n",
      "1250/1250 [==============================] - 417s 334ms/step - loss: 2.3174 - acc: 0.5158 - val_loss: 1.9321 - val_acc: 0.5761\n",
      "Epoch 11/75\n",
      "   2/1250 [..............................] - ETA: 5:37 - loss: 2.0013 - acc: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/anaconda3/envs/computer-vision/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.181148). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 405s 324ms/step - loss: 2.0789 - acc: 0.5357 - val_loss: 2.0290 - val_acc: 0.5334\n",
      "Epoch 12/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 2.0194 - acc: 0.5417 - val_loss: 1.7029 - val_acc: 0.5274\n",
      "Epoch 13/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 1.5982 - acc: 0.5609 - val_loss: 1.7997 - val_acc: 0.5596\n",
      "Epoch 14/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 1.4116 - acc: 0.5642 - val_loss: 1.3944 - val_acc: 0.5435\n",
      "Epoch 15/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 1.2180 - acc: 0.5835 - val_loss: 1.3941 - val_acc: 0.6155\n",
      "Epoch 16/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 1.0950 - acc: 0.6045 - val_loss: 1.0373 - val_acc: 0.6091\n",
      "Epoch 17/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.9758 - acc: 0.6341 - val_loss: 0.9731 - val_acc: 0.6695\n",
      "Epoch 18/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.9044 - acc: 0.6619 - val_loss: 0.8878 - val_acc: 0.6920\n",
      "Epoch 19/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.8480 - acc: 0.6893 - val_loss: 0.8413 - val_acc: 0.6924\n",
      "Epoch 20/75\n",
      "1250/1250 [==============================] - 402s 321ms/step - loss: 0.8201 - acc: 0.7075 - val_loss: 0.7844 - val_acc: 0.7516\n",
      "Epoch 21/75\n",
      "1250/1250 [==============================] - 402s 321ms/step - loss: 0.8018 - acc: 0.7294 - val_loss: 0.7727 - val_acc: 0.7548\n",
      "Epoch 22/75\n",
      "1250/1250 [==============================] - 407s 326ms/step - loss: 0.7674 - acc: 0.7443 - val_loss: 0.7154 - val_acc: 0.7963\n",
      "Epoch 23/75\n",
      "1250/1250 [==============================] - 407s 325ms/step - loss: 0.7466 - acc: 0.7564 - val_loss: 0.9056 - val_acc: 0.6820\n",
      "Epoch 24/75\n",
      "1250/1250 [==============================] - 409s 327ms/step - loss: 0.7251 - acc: 0.7672 - val_loss: 0.6793 - val_acc: 0.8144\n",
      "Epoch 25/75\n",
      "1250/1250 [==============================] - 406s 325ms/step - loss: 0.7125 - acc: 0.7780 - val_loss: 0.6930 - val_acc: 0.8023\n",
      "Epoch 26/75\n",
      "1250/1250 [==============================] - 405s 324ms/step - loss: 0.6937 - acc: 0.7888 - val_loss: 0.8055 - val_acc: 0.7307\n",
      "Epoch 27/75\n",
      "1250/1250 [==============================] - 405s 324ms/step - loss: 0.6725 - acc: 0.7973 - val_loss: 0.7637 - val_acc: 0.7496\n",
      "Epoch 28/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.6537 - acc: 0.8028 - val_loss: 0.5457 - val_acc: 0.8708\n",
      "Epoch 29/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.6402 - acc: 0.8097 - val_loss: 0.5529 - val_acc: 0.8639\n",
      "Epoch 30/75\n",
      "1250/1250 [==============================] - 406s 325ms/step - loss: 0.6376 - acc: 0.8146 - val_loss: 0.5623 - val_acc: 0.8671\n",
      "Epoch 31/75\n",
      "1250/1250 [==============================] - 405s 324ms/step - loss: 0.6264 - acc: 0.8149 - val_loss: 0.5791 - val_acc: 0.8414\n",
      "Epoch 32/75\n",
      "1250/1250 [==============================] - 405s 324ms/step - loss: 0.6133 - acc: 0.8228 - val_loss: 0.5943 - val_acc: 0.8575\n",
      "Epoch 33/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.6064 - acc: 0.8274 - val_loss: 0.6058 - val_acc: 0.8160\n",
      "Epoch 34/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.6031 - acc: 0.8262 - val_loss: 0.5296 - val_acc: 0.8635\n",
      "Epoch 35/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.6118 - acc: 0.8286 - val_loss: 0.5305 - val_acc: 0.8849\n",
      "Epoch 36/75\n",
      "1250/1250 [==============================] - 402s 321ms/step - loss: 0.6059 - acc: 0.8317 - val_loss: 0.5077 - val_acc: 0.8784\n",
      "Epoch 37/75\n",
      "1250/1250 [==============================] - 404s 324ms/step - loss: 0.5878 - acc: 0.8276 - val_loss: 0.5246 - val_acc: 0.8752\n",
      "Epoch 38/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5881 - acc: 0.8386 - val_loss: 0.5081 - val_acc: 0.8816\n",
      "Epoch 39/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5868 - acc: 0.8352 - val_loss: 0.4668 - val_acc: 0.9074\n",
      "Epoch 40/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5909 - acc: 0.8328 - val_loss: 0.6175 - val_acc: 0.8144\n",
      "Epoch 41/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5844 - acc: 0.8379 - val_loss: 0.4746 - val_acc: 0.8990\n",
      "Epoch 42/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5831 - acc: 0.8385 - val_loss: 0.5265 - val_acc: 0.8889\n",
      "Epoch 43/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5923 - acc: 0.8385 - val_loss: 0.5059 - val_acc: 0.8808\n",
      "Epoch 44/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5690 - acc: 0.8446 - val_loss: 0.4669 - val_acc: 0.9010\n",
      "Epoch 45/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5704 - acc: 0.8446 - val_loss: 0.5054 - val_acc: 0.8808\n",
      "Epoch 46/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.5761 - acc: 0.8426 - val_loss: 0.5006 - val_acc: 0.8736\n",
      "Epoch 47/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5610 - acc: 0.8452 - val_loss: 0.4693 - val_acc: 0.9058\n",
      "Epoch 48/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5651 - acc: 0.8461 - val_loss: 0.4503 - val_acc: 0.9062\n",
      "Epoch 49/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.5628 - acc: 0.8495 - val_loss: 0.4989 - val_acc: 0.8881\n",
      "Epoch 50/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5650 - acc: 0.8473 - val_loss: 0.4740 - val_acc: 0.8945\n",
      "Epoch 51/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5602 - acc: 0.8468 - val_loss: 0.4795 - val_acc: 0.8957\n",
      "Epoch 52/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5569 - acc: 0.8496 - val_loss: 0.5110 - val_acc: 0.8720\n",
      "Epoch 53/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5465 - acc: 0.8495 - val_loss: 0.4168 - val_acc: 0.9094\n",
      "Epoch 54/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5426 - acc: 0.8496 - val_loss: 0.5060 - val_acc: 0.8760\n",
      "Epoch 55/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5431 - acc: 0.8500 - val_loss: 0.4549 - val_acc: 0.9054\n",
      "Epoch 56/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5461 - acc: 0.8523 - val_loss: 0.5067 - val_acc: 0.8724\n",
      "Epoch 57/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.5472 - acc: 0.8510 - val_loss: 0.4553 - val_acc: 0.8994\n",
      "Epoch 58/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5350 - acc: 0.8561 - val_loss: 0.4294 - val_acc: 0.9098\n",
      "Epoch 59/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5430 - acc: 0.8520 - val_loss: 0.5009 - val_acc: 0.8704\n",
      "Epoch 60/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5331 - acc: 0.8532 - val_loss: 0.4141 - val_acc: 0.9050\n",
      "Epoch 61/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5299 - acc: 0.8587 - val_loss: 0.4539 - val_acc: 0.9042\n",
      "Epoch 62/75\n",
      "1250/1250 [==============================] - 403s 323ms/step - loss: 0.5321 - acc: 0.8559 - val_loss: 0.5093 - val_acc: 0.8647\n",
      "Epoch 63/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5241 - acc: 0.8571 - val_loss: 0.4510 - val_acc: 0.8945\n",
      "Epoch 64/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5329 - acc: 0.8546 - val_loss: 0.3902 - val_acc: 0.9255\n",
      "Epoch 65/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5230 - acc: 0.8558 - val_loss: 0.4299 - val_acc: 0.9078\n",
      "Epoch 66/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5227 - acc: 0.8595 - val_loss: 0.4517 - val_acc: 0.8953\n",
      "Epoch 67/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5213 - acc: 0.8562 - val_loss: 0.4133 - val_acc: 0.9086\n",
      "Epoch 68/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5226 - acc: 0.8574 - val_loss: 0.4360 - val_acc: 0.9090\n",
      "Epoch 69/75\n",
      "1250/1250 [==============================] - 404s 323ms/step - loss: 0.5261 - acc: 0.8604 - val_loss: 0.4251 - val_acc: 0.9155\n",
      "Epoch 70/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 402s 321ms/step - loss: 0.5291 - acc: 0.8601 - val_loss: 0.4484 - val_acc: 0.9050\n",
      "Epoch 71/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5201 - acc: 0.8616 - val_loss: 0.4218 - val_acc: 0.9094\n",
      "Epoch 72/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5210 - acc: 0.8610 - val_loss: 0.4212 - val_acc: 0.9130\n",
      "Epoch 73/75\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.5213 - acc: 0.8643 - val_loss: 0.4412 - val_acc: 0.9078\n",
      "Epoch 74/75\n",
      "1250/1250 [==============================] - 401s 321ms/step - loss: 0.5160 - acc: 0.8620 - val_loss: 0.4243 - val_acc: 0.9018\n",
      "Epoch 75/75\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 0.5091 - acc: 0.8645 - val_loss: 0.4629 - val_acc: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f623fd2e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the network\n",
    "model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // batch_size,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // batch_size,\n",
    "    epochs=75,\n",
    "    max_queue_size=batch_size * 2,\n",
    "    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing model...\n"
     ]
    }
   ],
   "source": [
    "# save the model to file\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(MODEL_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the HDF5 datasets\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from utils.image_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.image_preprocessor import ResizePreprocessor\n",
    "from utils.image_preprocessor import CropPreprocessor\n",
    "from utils.image_preprocessor import MeanPreprocessor\n",
    "\n",
    "from utils.hdf5_dataset_generator import HDF5DatasetGenerator\n",
    "\n",
    "from utils.ranked import rank_accuracy\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] predicting on test data (no crops)...\n",
      "[INFO] rank-1: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# load the RGB means for the training set\n",
    "means = json.loads(open(DATASET_MEAN).read())\n",
    "\n",
    "# initialize the image preprocessors\n",
    "rp = ResizePreprocessor(227, 227)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "cp = CropPreprocessor(227, 227)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# initialize the testing dataset generator, then make predictions on\n",
    "# the testing data\n",
    "print(\"[INFO] predicting on test data (no crops)...\")\n",
    "testGen = HDF5DatasetGenerator(TEST_HDF5, 64, preprocessors=[rp, mp, iap], classes=2)\n",
    "predictions = model.predict_generator(testGen.generator(), \n",
    "                                      steps=testGen.numImages // 64, max_queue_size=64 * 2)\n",
    "\n",
    "# compute the rank-1 and rank-5 accuracies\n",
    "(rank1, _) = rank_accuracy(predictions, testGen.db[\"labels\"])\n",
    "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
    "testGen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "Evaluating: N/A% |                                             | ETA:  --:--:--"
     ]
    }
   ],
   "source": [
    "# re-initialize the testing set generator, this time excluding the\n",
    "# ‘SimplePreprocessor‘\n",
    "testGen = HDF5DatasetGenerator(TEST_HDF5, 64, preprocessors=[mp], classes=2)\n",
    "predictions = []\n",
    "\n",
    "# initialize the progress bar\n",
    "widgets = [\"Evaluating: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=testGen.numImages // 64, widgets=widgets).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100% |#############################################| Time:  0:02:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting on test data (with crops)...\n",
      "[INFO] rank-1: 0.04%\n"
     ]
    }
   ],
   "source": [
    "# loop over a single pass of the test data\n",
    "for (i, (images, labels)) in enumerate(testGen.generator(passes=1)):\n",
    "    # loop over each of the individual images\n",
    "    for image in images:\n",
    "        # apply the crop preprocessor to the image to generate 10\n",
    "        # separate crops, then convert them from images to arrays\n",
    "        crops = cp.preprocess(image)\n",
    "        crops = np.array([iap.preprocess(c) for c in crops], dtype=\"float32\")\n",
    "                                                                                                                                                                                                                                                                                                                    \n",
    "        # make predictions on the crops and then average them\n",
    "        # together to obtain the final prediction\n",
    "        pred = model.predict(crops)\n",
    "        predictions.append(pred.mean(axis=0))\n",
    "        \n",
    "    # update the progress bar\n",
    "    pbar.update(i)\n",
    "    \n",
    "# compute the rank-1 accuracy\n",
    "pbar.finish()\n",
    "print(\"[INFO] predicting on test data (with crops)...\")\n",
    "(rank1, _) = rank_accuracy(predictions, testGen.db[\"labels\"])\n",
    "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
    "testGen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
