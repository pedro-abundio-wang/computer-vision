{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training AlexNet on Kaggle: Dogs vs. Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "\n",
    "# import the necessary packages\n",
    "from utils.image_preprocessor import ImageToArrayPreprocessor\n",
    "from utils.image_preprocessor import PatchPreprocessor\n",
    "from utils.image_preprocessor import MeanPreprocessor\n",
    "from utils.hdf5_dataset_generator import HDF5DatasetGenerator\n",
    "from classifiers.alexnet import AlexNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pyimagesearch.callbacks import TrainingMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths to the images directory\n",
    "IMAGES_PATH = \"./datasets/kaggle_dogs_vs_cats/train\"\n",
    "\n",
    "# since we do not have validation data or access to the testing\n",
    "# labels we need to take a number of images from the training\n",
    "# data and use them instead\n",
    "NUM_CLASSES = 2\n",
    "NUM_VAL_IMAGES = 1250 * NUM_CLASSES\n",
    "NUM_TEST_IMAGES = 1250 * NUM_CLASSES\n",
    "\n",
    "# define the path to the output training, validation, and testing\n",
    "# HDF5 files\n",
    "TRAIN_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/train.hdf5\"\n",
    "VAL_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/val.hdf5\"\n",
    "TEST_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/test.hdf5\"\n",
    "\n",
    "# path to the output model file\n",
    "MODEL_PATH = \"./output/kaggle_dogs_vs_cats/alexnet_dogs_vs_cats.model\"\n",
    "\n",
    "# define the path to the dataset mean\n",
    "DATASET_MEAN = \"./output/kaggle_dogs_vs_cats/dogs_vs_cats_mean.json\"\n",
    "\n",
    "# define the path to the output directory used for storing plots,\n",
    "# classification reports, etc.\n",
    "OUTPUT_PATH = \"./output/kaggle_dogs_vs_cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, \n",
    "                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, \n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RGB means for the training set\n",
    "means = json.loads(open(DATASET_MEAN).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image preprocessors\n",
    "sp = SimplePreprocessor(227, 227)\n",
    "pp = PatchPreprocessor(227, 227)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training and validation dataset generators\n",
    "trainGen = HDF5DatasetGenerator(TRAIN_HDF5, 128, aug=aug, preprocessors=[pp, mp, iap], classes=2)\n",
    "valGen = HDF5DatasetGenerator(VAL_HDF5, 128, preprocessors=[sp, mp, iap], classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = AlexNet.build(width=227, height=227, depth=3, classes=2, reg=0.0002)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# construct the set of callbacks\n",
    "path = os.path.sep.join([config.OUTPUT_PATH, \"{}.png\".format(os.getpid())])\n",
    "callbacks = [TrainingMonitor(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // 128,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // 128,\n",
    "    epochs=75,\n",
    "    max_queue_size=128 * 2,\n",
    "    callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(MODEL_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the HDF5 datasets\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from config import dogs_vs_cats_config as config\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import SimplePreprocessor\n",
    "from pyimagesearch.preprocessing import MeanPreprocessor\n",
    "from pyimagesearch.preprocessing import CropPreprocessor\n",
    "from pyimagesearch.io import HDF5DatasetGenerator\n",
    "from pyimagesearch.utils.ranked import rank5_accuracy\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RGB means for the training set\n",
    "means = json.loads(open(config.DATASET_MEAN).read())\n",
    "\n",
    "# initialize the image preprocessors\n",
    "sp = SimplePreprocessor(227, 227)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "cp = CropPreprocessor(227, 227)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model(config.MODEL_PATH)\n",
    "\n",
    "# initialize the testing dataset generator, then make predictions on\n",
    "# the testing data\n",
    "print(\"[INFO] predicting on test data (no crops)...\")\n",
    "testGen = HDF5DatasetGenerator(config.TEST_HDF5, 64, preprocessors=[sp, mp, iap], classes=2)\n",
    "predictions = model.predict_generator(testGen.generator(), \n",
    "                                      steps=testGen.numImages // 64, max_queue_size=64 * 2)\n",
    "\n",
    "# compute the rank-1 and rank-5 accuracies\n",
    "(rank1, _) = rank5_accuracy(predictions, testGen.db[\"labels\"])\n",
    "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
    "testGen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the testing set generator, this time excluding the\n",
    "# ‘SimplePreprocessor‘\n",
    "testGen = HDF5DatasetGenerator(config.TEST_HDF5, 64, preprocessors=[mp], classes=2)\n",
    "predictions = []\n",
    "\n",
    "# initialize the progress bar\n",
    "widgets = [\"Evaluating: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=testGen.numImages // 64, widgets=widgets).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over a single pass of the test data\n",
    "for (i, (images, labels)) in enumerate(testGen.generator(passes=1)):\n",
    "    # loop over each of the individual images\n",
    "    for image in images:\n",
    "        # apply the crop preprocessor to the image to generate 10\n",
    "        # separate crops, then convert them from images to arrays\n",
    "        crops = cp.preprocess(image)\n",
    "        crops = np.array([iap.preprocess(c) for c in crops], dtype=\"float32\")\n",
    "        \n",
    "        # make predictions on the crops and then average them\n",
    "        # together to obtain the final prediction\n",
    "        pred = model.predict(crops)\n",
    "        predictions.append(pred.mean(axis=0))\n",
    "        \n",
    "    # update the progress bar\n",
    "    pbar.update(i)\n",
    "    \n",
    "# compute the rank-1 accuracy\n",
    "pbar.finish()\n",
    "print(\"[INFO] predicting on test data (with crops)...\")\n",
    "(rank1, _) = rank5_accuracy(predictions, testGen.db[\"labels\"])\n",
    "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
    "testGen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
