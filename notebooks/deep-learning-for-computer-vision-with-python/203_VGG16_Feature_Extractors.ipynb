{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Feature Extractors CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear  \n",
    "# inline in the notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyimagesearch.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to input dataset\n",
    "dataset = \n",
    "# path to output HDF5 file\n",
    "output = './output/hdf5/vgg16-cifar10-features.hdf5'\n",
    "# batch size of images to be passed through network, default=32\n",
    "batch-size = 32\n",
    "# size of feature extraction buffer, default=1000\n",
    "buffer-size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# initialize the HDF5 dataset writer, then store the class label names in the dataset\n",
    "dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7), \n",
    "                            args[\"output\"], dataKey=\"features\", bufSize=args[\"buffer_size\"]) \n",
    "\n",
    "dataset.storeClassLabels(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the progress bar\n",
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths), widgets=widgets).start()\n",
    "\n",
    "# loop over the images in patches\n",
    "for i in np.arange(0, len(imagePaths), bs):\n",
    "    # extract the batch of images and labels, then initialize the\n",
    "    # list of actual images that will be passed through the network\n",
    "    # for feature extraction\n",
    "    batchPaths = imagePaths[i:i + bs]\n",
    "    batchLabels = labels[i:i + bs]\n",
    "    batchImages = []\n",
    "    \n",
    "    # loop over the images and labels in the current batch\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        # load the input image using the Keras helper utility\n",
    "        # while ensuring the image is resized to 224x224 pixels\n",
    "        image = load_img(imagePath, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        # preprocess the image by (1) expanding the dimensions and\n",
    "        # (2) subtracting the mean RGB pixel intensity from the\n",
    "        # ImageNet dataset\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "        # add the image to the batch\n",
    "        batchImages.append(image)\n",
    "        \n",
    "    # pass the images through the network and use the outputs as our actual features\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size=bs)\n",
    "    \n",
    "    # reshape the features so that each image is represented by\n",
    "    # a flattened feature vector of the ‘MaxPooling2D‘ outputs\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "\n",
    "    # add the features and labels to our HDF5 dataset\n",
    "    dataset.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "    \n",
    "# close the dataset\n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Feature Extractors CALTECH101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = './output/hdf5/vgg16-caltech101-features.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on Extracted Features CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the arguments\n",
    "# path HDF5 database\n",
    "db = \n",
    "# path to output model\n",
    "model =\n",
    "# num of jobs to run when tuning hyperparameters\n",
    "jobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the HDF5 database for reading then determine the index of\n",
    "# the training and testing split, provided that this data was\n",
    "# already shuffled *prior* to writing it to disk\n",
    "db = h5py.File(args[\"db\"], \"r\")\n",
    "i = int(db[\"labels\"].shape[0] * 0.75)\n",
    "\n",
    "# define the set of parameters that we want to tune then start a\n",
    "# grid search where we evaluate our model for each value of C\n",
    "print(\"[INFO] tuning hyperparameters...\")\n",
    "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
    "model = GridSearchCV(LogisticRegression(), params, cv=3, n_jobs=args[\"jobs\"])\n",
    "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
    "print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n",
    "\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(db[\"features\"][i:])\n",
    "print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(args[\"model\"], \"wb\")\n",
    "f.write(pickle.dumps(model.best_estimator_))\n",
    "f.close()\n",
    "\n",
    "# close the database\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on Extracted Features Caltech101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
