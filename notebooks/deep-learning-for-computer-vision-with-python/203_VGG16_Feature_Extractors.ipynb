{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Feature Extractors CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear  \n",
    "# inline in the notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.hdf5_dataset_writer import HDF5DatasetWriter\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import random\n",
    "import os\n",
    "\n",
    "from utils.image_preprocessor import ImagePreprocessor\n",
    "from utils.image_preprocessor import ResizePreprocessor\n",
    "from utils.image_preprocessor import ImageToArrayPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX[:sample_num]\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainY[:sample_num]\n",
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap = ResizePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "ip = ImagePreprocessor(preprocessors=[aap, iap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = ip.preprocess(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to output HDF5 file\n",
    "output = './output/feature_persistence/vgg16-cifar10-features.hdf5'\n",
    "# batch size of images to be passed through network, default=32\n",
    "batch_size = 32\n",
    "# size of feature extraction buffer, default=1000\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# initialize the HDF5 dataset writer, then store the class label names in the dataset\n",
    "dataset = HDF5DatasetWriter((sample_num, 512 * 7 * 7), output, dataKey=\"features\", bufSize=buffer_size) \n",
    "dataset.storeClassLabels(labelNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the progress bar\n",
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=sample_num, widgets=widgets).start()\n",
    "\n",
    "# loop over the images in patches\n",
    "for i in np.arange(0, sample_num, batch_size):\n",
    "    # extract the batch of images and labels, then initialize the\n",
    "    # list of actual images that will be passed through the network\n",
    "    # for feature extraction\n",
    "    batchImages = trainX[i:i + batch_size]\n",
    "    batchLabels = trainY[i:i + batch_size]\n",
    "    batchLabels = np.squeeze(batchLabels)\n",
    "    \n",
    "    # subtracting the mean RGB pixel intensity from the ImageNet dataset\n",
    "    batchImages = imagenet_utils.preprocess_input(batchImages)\n",
    "    \n",
    "    # pass the images through the network and use the outputs as our actual features\n",
    "    features = model.predict(batchImages, batch_size=batch_size)\n",
    "    \n",
    "    # reshape the features so that each image is represented by\n",
    "    # a flattened feature vector of the ‘MaxPooling2D‘ outputs\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "\n",
    "    # add the features and labels to our HDF5 dataset\n",
    "    dataset.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "    \n",
    "# close the dataset\n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "db = h5py.File(output)\n",
    "list(db.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on Extracted Features CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the arguments\n",
    "# path HDF5 database\n",
    "output = './output/feature_persistence/vgg16-cifar10-features.hdf5'\n",
    "# path to output model\n",
    "model_path = './output/feature_persistence/vgg16-cifar10-model.cpickle'\n",
    "# num of jobs to run when tuning hyperparameters\n",
    "jobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the HDF5 database for reading then determine the index of\n",
    "# the training and testing split, provided that this data was\n",
    "# already shuffled *prior* to writing it to disk\n",
    "db = h5py.File(output, \"r\")\n",
    "i = int(db[\"labels\"].shape[0] * 0.75)\n",
    "\n",
    "# define the set of parameters that we want to tune then start a\n",
    "# grid search where we evaluate our model for each value of C\n",
    "print(\"[INFO] tuning hyperparameters...\")\n",
    "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
    "model = GridSearchCV(LogisticRegression(), params, cv=3, n_jobs=jobs)\n",
    "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
    "print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n",
    "\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(db[\"features\"][i:])\n",
    "print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(model_path, \"wb\")\n",
    "f.write(pickle.dumps(model.best_estimator_))\n",
    "f.close()\n",
    "\n",
    "# close the database\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
