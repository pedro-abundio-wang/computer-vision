{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle_Dogs_vs_Cats_HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths to the images directory\n",
    "IMAGES_PATH = \"./datasets/kaggle_dogs_vs_cats/train\"\n",
    "\n",
    "# since we do not have validation data or access to the testing\n",
    "# labels we need to take a number of images from the training\n",
    "# data and use them instead\n",
    "NUM_CLASSES = 2\n",
    "NUM_VAL_IMAGES = 1250 * NUM_CLASSES\n",
    "NUM_TEST_IMAGES = 1250 * NUM_CLASSES\n",
    "\n",
    "# define the path to the output training, validation, and testing\n",
    "# HDF5 files\n",
    "TRAIN_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/train.hdf5\"\n",
    "VAL_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/val.hdf5\"\n",
    "TEST_HDF5 = \"./datasets/kaggle_dogs_vs_cats/hdf5/test.hdf5\"\n",
    "\n",
    "# path to the output model file\n",
    "MODEL_PATH = \"./output/kaggle_dogs_vs_cats/alexnet_dogs_vs_cats.model\"\n",
    "\n",
    "# define the path to the dataset mean\n",
    "DATASET_MEAN = \"./output/kaggle_dogs_vs_cats/dogs_vs_cats_mean.json\"\n",
    "\n",
    "# define the path to the output directory used for storing plots,\n",
    "# classification reports, etc.\n",
    "OUTPUT_PATH = \"./output/kaggle_dogs_vs_cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.image_preprocessor import AspectAwarePreprocessor\n",
    "from utils.hdf5_dataset_writer import HDF5DatasetWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the paths to the images\n",
    "trainPaths = glob.glob(IMAGES_PATH + \"/*.jpg\")\n",
    "trainLabels = [p.split(os.path.sep)[-1].split(\".\")[0] for p in trainPaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "trainLabels = le.fit_transform(trainLabels)\n",
    "\n",
    "# perform stratified sampling from the training set to build the\n",
    "# testing split from the training data\n",
    "split = train_test_split(trainPaths, trainLabels, test_size=NUM_TEST_IMAGES, \n",
    "                         stratify=trainLabels, random_state=42)\n",
    "(trainPaths, testPaths, trainLabels, testLabels) = split\n",
    "\n",
    "# perform another stratified sampling, this time to build the\n",
    "# validation data\n",
    "split = train_test_split(trainPaths, trainLabels, test_size=NUM_VAL_IMAGES, \n",
    "                         stratify=trainLabels, random_state=42)\n",
    "(trainPaths, valPaths, trainLabels, valLabels) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a list pairing the training, validation, and testing\n",
    "# image paths along with their corresponding labels and output HDF5\n",
    "# files\n",
    "datasets = [\n",
    "    (\"train\", trainPaths, trainLabels, TRAIN_HDF5),\n",
    "    (\"val\", valPaths, valLabels, VAL_HDF5),\n",
    "    (\"test\", testPaths, testLabels, TEST_HDF5)]\n",
    "\n",
    "# initialize the image preprocessor and the lists of RGB channel averages\n",
    "aap = AspectAwarePreprocessor(256, 256)\n",
    "(R, G, B) = ([], [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataset tuples\n",
    "for (dType, paths, labels, outputPath) in datasets:\n",
    "    # create HDF5 writer\n",
    "    print(\"[INFO] building {}...\".format(outputPath))\n",
    "    writer = HDF5DatasetWriter((len(paths), 256, 256, 3), outputPath)\n",
    "    \n",
    "    # initialize the progress bar\n",
    "    widgets = [\"Building Dataset: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "    pbar = progressbar.ProgressBar(maxval=len(paths), widgets=widgets).start()\n",
    "    \n",
    "    # loop over the image paths\n",
    "    for (i, (path, label)) in enumerate(zip(paths, labels)):\n",
    "        # load the image and process it\n",
    "        image = cv2.imread(path)\n",
    "        image = aap.preprocess(image)\n",
    "        # if we are building the training dataset, then compute the\n",
    "        # mean of each channel in the image, then update the\n",
    "        # respective lists\n",
    "        if dType == \"train\":\n",
    "            (b, g, r) = cv2.mean(image)[:3]\n",
    "            R.append(r)\n",
    "            G.append(g)\n",
    "            B.append(b)\n",
    "        \n",
    "        # add the image and label # to the HDF5 dataset\n",
    "        writer.add([image], [label])\n",
    "        pbar.update(i)\n",
    "        \n",
    "    # close the HDF5 writer\n",
    "    pbar.finish()\n",
    "    writer.close()\n",
    "    \n",
    "# construct a dictionary of averages, then serialize the means to a JSON file\n",
    "print(\"[INFO] serializing means...\")\n",
    "D = {\"R\": np.mean(R), \"G\": np.mean(G), \"B\": np.mean(B)}\n",
    "f = open(DATASET_MEAN, \"w\")\n",
    "f.write(json.dumps(D))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
