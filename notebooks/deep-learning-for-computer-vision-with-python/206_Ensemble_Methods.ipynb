{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from classifiers.mini_vgg import MiniVGGNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to output directory\n",
    "output = \"./output/ensemble_method\"\n",
    "# path to output models directory\n",
    "models = \"./output/ensemble_method\"\n",
    "# num of models to train\n",
    "num_models = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data, then scale it into the range [0, 1]\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "labelBinarizer = LabelBinarizer()\n",
    "trainY = labelBinarizer.fit_transform(trainY)\n",
    "testY = labelBinarizer.fit_transform(testY)\n",
    "\n",
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "                         height_shift_range=0.1, horizontal_flip=True, \n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop over the number of models to train\n",
    "for i in np.arange(0, num_models):\n",
    "    # initialize the optimizer and model\n",
    "    print(\"[INFO] training model {}/{}\".format(i + 1, num_models))\n",
    "    opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "    model = MiniVGGNet().build(width=32, height=32, depth=3, classes=10)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    # train the network\n",
    "    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=64), \n",
    "                            validation_data=(testX, testY), epochs=40, \n",
    "                            steps_per_epoch=len(trainX) // 64, verbose=1)\n",
    "\n",
    "    # save the model to disk\n",
    "    p = [models, \"model_{}.model\".format(i)]\n",
    "    model.save(os.path.sep.join(p))\n",
    "\n",
    "    # evaluate the network\n",
    "    predictions = model.predict(testX, batch_size=64)\n",
    "    report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames)\n",
    "\n",
    "    # save the classification report to file\n",
    "    p = [output, \"model_{}.txt\".format(i)]\n",
    "    f = open(os.path.sep.join(p), \"w\")\n",
    "    f.write(report)\n",
    "    f.close()\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    p = [output, \"model_{}.png\".format(i)]\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 40), H.history[\"loss\"],\n",
    "    label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"val_loss\"],\n",
    "    label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"acc\"],\n",
    "    label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"val_acc\"],\n",
    "    label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy for model {}\".format(i))\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.sep.join(p))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# load the testing data, then scale it into the range [0, 1]\n",
    "(testX, testY) = cifar10.load_data()[1]\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "testY = lb.fit_transform(testY)\n",
    "\n",
    "# construct the path used to collect the models then initialize the\n",
    "# models list\n",
    "modelPaths = list(glob.glob('./output/ensemble_method/*.model'))\n",
    "models = []\n",
    "\n",
    "# loop over the model paths, loading the model, and adding it to\n",
    "# the list of models\n",
    "for (i, modelPath) in enumerate(modelPaths):\n",
    "    print(\"[INFO] loading model {}/{}\".format(i + 1, len(modelPaths)))\n",
    "    models.append(load_model(modelPath))\n",
    "\n",
    "# initialize the list of predictions\n",
    "print(\"[INFO] evaluating ensemble...\")\n",
    "predictions = []\n",
    "\n",
    "# loop over the models\n",
    "for model in models:\n",
    "    # use the current model to make predictions on the testing data,\n",
    "    # then store these predictions in the aggregate predictions list\n",
    "    predictions.append(model.predict(testX, batch_size=64))\n",
    "\n",
    "# average the probabilities across all model predictions, then show\n",
    "# a classification report\n",
    "predictions = np.average(predictions, axis=0)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Snapshot Ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
