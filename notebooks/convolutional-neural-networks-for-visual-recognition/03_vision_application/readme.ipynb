{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement **recurrent networks**, and apply them to **image captioning on Microsoft COCO**. You will also explore methods for **visualizing the features of a pretrained model on ImageNet**, and also this model to implement **Style Transfer**. Finally, you will train a **Generative Adversarial Network** to **generate images** that look like a training dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals of this notebook are as follows:\n",
    "\n",
    "- Understand the architecture of **recurrent neural networks (RNNs)** and how they operate on sequences by sharing weights over time\n",
    "- Understand and implement both **Vanilla RNNs** and **Long-Short Term Memory (LSTM)** networks.\n",
    "- Understand how to **combine** **convolutional neural nets** and **recurrent nets** to implement an **image captioning system**\n",
    "- Explore various applications of **image gradients**, including **saliency maps, fooling images, class visualizations**\n",
    "- Understand and implement techniques for **image style transfer**\n",
    "- Understand how to train and implement a **Generative Adversarial Network (GAN)** to produce images that resemble samples from a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data:\n",
    "Once you have the starter code, you will need to get the **COCO captioning data**, **pretrained SqueezeNet model (TensorFlow-only)**, and a few **ImageNet validation images**\n",
    "\n",
    "**COCO captioning data**:\n",
    "\n",
    "**pretrained SqueezeNet model**:\n",
    "\n",
    "**ImageNet validation images**:\n",
    "\n",
    "Run the following from the **datasets** directory:\n",
    "\n",
    "```bash\n",
    "cd utils/datasets\n",
    "./get_assignment3_data.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Image Captioning with Vanilla RNNs (25 points)\n",
    "The Jupyter notebook **RNN_Captioning.ipynb** will walk you through the implementation of an image captioning system on MS-COCO using vanilla recurrent networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Image Captioning with LSTMs (30 points)\n",
    "The Jupyter notebook **LSTM_Captioning.ipynb** will walk you through the implementation of Long-Short Term Memory (LSTM) RNNs, and apply them to image captioning on MS-COCO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images (15 points)\n",
    "The Jupyter notebooks **NetworkVisualization-TensorFlow.ipynb** and **NetworkVisualization-PyTorch.ipynb** will introduce the pretrained SqueezeNet model, compute gradients with respect to images, and use them to produce saliency maps and fooling images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Style Transfer (15 points)\n",
    "In the Jupyter notebooks **StyleTransfer-TensorFlow.ipynb** and **StyleTransfer-PyTorch.ipynb** you will learn how to create images with the content of one image but the style of another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Generative Adversarial Networks (15 points)\n",
    "In the Jupyter notebooks **GANS-TensorFlow.ipynb** and **GANS-PyTorch.ipynb** you will learn how to generate images that match a training dataset, and use these models to improve classifier performance when training on a large amount of unlabeled data and a small amount of labeled data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
